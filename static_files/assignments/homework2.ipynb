{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfmanberg/CS506-Fall2025/blob/main/static_files/assignments/homework2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DS 542 Homework 2\n",
        "\n",
        "In this homework, you will use the image model Stable Diffusion to reproduce a new photo that is not in its training data.\n"
      ],
      "metadata": {
        "id": "qaaSvEfj-YkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "\n",
        "1. Make a copy of this notebook (e.g. File -> Save a Copy in Drive).\n",
        "2. Filling in the necessary code for each problem below, and run your notebook to show that your code works.\n",
        "3. Save your notebook (Colab does this automatically, must be done for VS Code).\n",
        "4. Upload your notebook to Gradescope."
      ],
      "metadata": {
        "id": "-nMvpXdgDeGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module Setup"
      ],
      "metadata": {
        "id": "BrPj_dkODBeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECaoHcHZzVZ1"
      },
      "outputs": [],
      "source": [
        "!pip install -q keras-core --upgrade\n",
        "!pip install -q keras-cv --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\""
      ],
      "metadata": {
        "id": "kgMO7aiQzaAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio.v2 as imageio\n",
        "import keras_core as keras\n",
        "import keras_cv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import skimage\n",
        "import torch\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "D0u4Zr_34V2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU Setup"
      ],
      "metadata": {
        "id": "X6C0gi65_nDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# autodetect GPU availability in Google Colab.\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE\", DEVICE)\n",
        "torch.set_default_device(DEVICE)\n",
        "\n",
        "torch.tensor([[0.0, 0.1, 0.4, 0.3, 0.5]])"
      ],
      "metadata": {
        "id": "ZIH6cYLK0rYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Test Stable Diffusion"
      ],
      "metadata": {
        "id": "9IWGgzya_0na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras_cv.models.StableDiffusion(img_width=256, img_height=256)"
      ],
      "metadata": {
        "id": "zfYbFGSZ0t8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images):\n",
        "    # Original version from https://colab.research.google.com/gist/jbischof/ef9dde655d1c230b66abaf9eb54e1ad0/stable-diffusion-keras-core-jax.ipynb\n",
        "    if isinstance(images, torch.Tensor):\n",
        "        images = images.detach().cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "6Fh7EkT3-gm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert Stable Diffusion latent code into an image with [0-1] color values.\n",
        "\n",
        "def decode_latent(latent):\n",
        "    decoded = model.decoder.forward(latent)\n",
        "\n",
        "    # remap output range from zero centered to roughly [0,1]\n",
        "    decoded = ((decoded + 1) / 2) # * 255\n",
        "\n",
        "    # really limit the output range to [0,1]\n",
        "    decoded = torch.clamp(decoded, 0.0, 1.0)\n",
        "\n",
        "    return decoded\n",
        "\n",
        "random_latent = torch.randn(1, 32, 32, 4, device=DEVICE)\n",
        "random_latent_image = decode_latent(random_latent)\n",
        "plot_images(random_latent_image)"
      ],
      "metadata": {
        "id": "QFF7ITM-w8C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1: Load Target Image\n",
        "\n",
        "1. Take a photo that is personal to you.\n",
        "    * Some part of the subject must be personal to you. This could be a selfie, a handwritten version of your name (other languages/scripts welcome), or even a picture of your hand.\n",
        "    * It must include something indicating the current date (e.g. September 2025) such as writing the date or showing the current page of the Daily Free Press.\n",
        "    * Resize this image to 256x256 pixels.\n",
        "    * Do this image prep however you like - it does not need to be in the notebook.\n",
        "2. Load the image as a variable `target_image` in this notebook and normalize it as follows.\n",
        "    * `imageio.imread` will be useful for the initial load.\n",
        "    * `target_image` should be a [PyTorch tensor](https://docs.pytorch.org/docs/stable/tensors.html) with data type `torch.float32`.\n",
        "    * The dimensions should be 1x256x256x3. The one is for a \"batch size\" -- just this one image. The three is for red/green/blue color channels. PyTorch has view and reshaping functions similar to NumPy.\n"
      ],
      "metadata": {
        "id": "JBpfXhoP6pVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# load your photo into the variable target_image_original variable\n",
        "\n",
        "target_image_original = ...\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oEhSoHpLu7hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this code might be helpful to get your image into target_image\n",
        "# in the right format\n",
        "\n",
        "# YOUR CHANGES HERE\n",
        "\n",
        "target_image = target_image_original\n",
        "target_image = torch.tensor(target_image, dtype=torch.float32)\n",
        "if target_image_original.dtype == numpy.uint8:\n",
        "    target_image = target_image / 255.0\n",
        "\n",
        "target_image = target_image.view(1, *target_image.shape)\n"
      ],
      "metadata": {
        "id": "iTSsr3G16e67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot your image to make sure\n",
        "\n",
        "print(\"SHAPE\", target_image.shape,\n",
        "      \"MIN\", target_image.min().item(),\n",
        "      \"MAX\", target_image.max().item(),\n",
        "      \"DTYPE\", target_image.dtype)\n",
        "plot_images(target_image)"
      ],
      "metadata": {
        "id": "d34Th9qW6YZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2: Pick a Loss Function\n",
        "\n",
        "1. Implement the function `compute_loss` below that takes in an output image and a target image.\n",
        "    * If the images are identical, the output should be zero.\n",
        "    * If the images are different, the output should be positive.\n",
        "    * The computation should be differentiable.\n"
      ],
      "metadata": {
        "id": "Gb5L8tdR__2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "def compute_loss(output, target):\n",
        "  #MSE? loss = torch.sum\n",
        "    # YOUR CHANGES HERE\n",
        "    return ...\n"
      ],
      "metadata": {
        "id": "BXK16BUT4_ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check your loss function\n",
        "\n",
        "random_latent_loss = compute_loss(random_latent_image, target_image)\n",
        "print(\"RANDOM LATENT LOSS\", random_latent_loss.item())\n",
        "\n",
        "target_loss = compute_loss(target_image, target_image)\n",
        "print(\"TARGET IMAGE LOSS\", target_loss.item())"
      ],
      "metadata": {
        "id": "lR6rdDZQAYy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3: Make Stable Diffusion Output Your Image\n",
        "\n",
        "The following code uses a simplified PyTorch training loop to optimize a Stable Diffusion latent code to reproduce your image.\n",
        "**Make whatever changes that you deem necessary** so that it finds a latent code encoding an image very similar to your original image.\n",
        "\n",
        "Make sure to check the output image really matches!\n",
        "The cells following the training loop will help you check how fast progress was made and the quality of your result."
      ],
      "metadata": {
        "id": "Mvi46c4GAegR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CHANGES HERE\n",
        "#ITERATIONS\n",
        "\n",
        "latent = torch.randn(1, 32, 32, 4, requires_grad=True)\n",
        "\n",
        "# UPPER BOUND ON NUMBER OF OPTIMIZATION STEPS\n",
        "steps=100 #CHANGE HERE\n",
        "\n",
        "decoded_images = []\n",
        "optimizer = torch.optim.Adam([latent], lr=1e-1) #CHANGE HERE\n",
        "for step in tqdm.tqdm(range(steps), desc=\"Optimizing latents\"):\n",
        "    optimizer.zero_grad()\n",
        "    latent.retain_grad()\n",
        "\n",
        "    decoded_image = decode_latent(latent)\n",
        "    # save a copy of the image that is disconnected from gradient tracking.\n",
        "    decoded_images.append(decoded_image.detach())\n",
        "\n",
        "    # compute an appropriate loss function to guide the output to match your target image.\n",
        "\n",
        "    loss = compute_loss(decoded_image, target_image)\n",
        "\n",
        "    # compute gradients with backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # optimize the latent code based on the gradients.\n",
        "    optimizer.step()\n",
        "\n",
        "    # occasionally print out loss value\n",
        "    if (step + 1) % (steps // 10) == 0:\n",
        "        print(\"\")\n",
        "        print(\"LOSS\", loss.item())\n",
        "\n",
        "    # stop when loss is small.\n",
        "    # CHANGE THIS THRESHOLD if not appropriate for your loss function.\n",
        "    if loss.item() < 1e-2: #CHANGES HERE\n",
        "        break\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "overall_loss = compute_loss(decoded_image, target_image)\n",
        "print(\"OVERALL LOSS\", overall_loss.item())\n",
        "\n",
        "decoded_images = torch.cat(decoded_images, dim=0)\n",
        "num_images = decoded_images.shape[0]\n",
        "print(\"NUM IMAGES\", num_images)\n"
      ],
      "metadata": {
        "id": "jVGrQuGHy101"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot 10 of the images to show the progress\n",
        "plot_images(decoded_images[num_images//10-1::(num_images+9)//10,:,:])\n"
      ],
      "metadata": {
        "id": "I7zdrKAD6LsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_image = decoded_image[-1:,:,:,:]\n",
        "\n",
        "diff_image = (target_image - last_image).abs()\n",
        "\n",
        "comparison_images = torch.cat([target_image, last_image, diff_image, diff_image / diff_image.max()], dim=0)\n",
        "plot_images(comparison_images)"
      ],
      "metadata": {
        "id": "uNCYdoM0iBuV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}